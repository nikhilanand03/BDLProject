[2024-05-19 02:34:30,791] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: keypoints_dag.fetch_data manual__2024-05-18T21:04:07.629303+00:00 [queued]>
[2024-05-19 02:34:30,794] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: keypoints_dag.fetch_data manual__2024-05-18T21:04:07.629303+00:00 [queued]>
[2024-05-19 02:34:30,794] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-19 02:34:30,794] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-05-19 02:34:30,794] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-19 02:34:30,798] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): fetch_data> on 2024-05-18 21:04:07.629303+00:00
[2024-05-19 02:34:30,807] {standard_task_runner.py:52} INFO - Started process 36072 to run task
[2024-05-19 02:34:30,811] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'keypoints_dag', 'fetch_data', 'manual__2024-05-18T21:04:07.629303+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/preprocess_airflow.py', '--cfg-path', '/var/folders/hr/cn8gd6d15xv_6m22yptdtyhw0000gn/T/tmprq1n6akc', '--error-file', '/var/folders/hr/cn8gd6d15xv_6m22yptdtyhw0000gn/T/tmpogz87rk5']
[2024-05-19 02:34:30,812] {standard_task_runner.py:77} INFO - Job 12: Subtask fetch_data
[2024-05-19 02:34:30,835] {logging_mixin.py:109} INFO - Running <TaskInstance: keypoints_dag.fetch_data manual__2024-05-18T21:04:07.629303+00:00 [running]> on host 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa
[2024-05-19 02:34:30,854] {taskinstance.py:1424} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=keypoints_dag
AIRFLOW_CTX_TASK_ID=fetch_data
AIRFLOW_CTX_EXECUTION_DATE=2024-05-18T21:04:07.629303+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-05-18T21:04:07.629303+00:00
[2024-05-19 02:34:30,854] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/hr/cn8gd6d15xv_6m22yptdtyhw0000gn/T
[2024-05-19 02:34:30,855] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -o /Users/nikhilanand/BDLProject/data/train.zip "https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/62891/6855609/compressed/training.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1716100019&Signature=cz%2FG3wvyhW9QcUGYEAJ2bNXo6%2FIgCjqrbvxZGtyEC7%2BuoZkfBknQIlCuccOA82cjZjppreHd9XQcWXHNVvudXozi1iJJhcQzdZoqUzMux3lrBSZGGtZ%2BTYufw53k5WMQ2ByF%2Fm%2FhqJSjTlijkZOfRMJgbJkvGIcbMwIZxOwmXho%2FQjn6XGxSTsbNYaBfDl9%2FFtxqUz7eM42Y6WHzRbCbinHh0NqnRIAWNwh6ixYM7GRdSVhJiMmS7Ed9oLMvTUQBgi6qgyRB5BDejTJ6v31mCQdJcO0Nb53bbmzxl42nFMnBEtw3HhVgkD4rJcDbQXiWLRs0C1rKC5w2jGDA2c10sw%3D%3D&response-content-disposition=attachment%3B+filename%3Dtraining.csv.zip"']
[2024-05-19 02:34:30,865] {subprocess.py:85} INFO - Output:
[2024-05-19 02:34:30,879] {subprocess.py:89} INFO -   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
[2024-05-19 02:34:30,879] {subprocess.py:89} INFO -                                  Dload  Upload   Total   Spent    Left  Speed
[2024-05-19 02:34:55,173] {subprocess.py:89} INFO -   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0 54.6M    0 24474    0     0  27196      0  0:35:05 --:--:--  0:35:05 27193  0 54.6M    0  262k    0     0   145k      0  0:06:23  0:00:01  0:06:22  145k  3 54.6M    3 1806k    0     0   644k      0  0:01:26  0:00:02  0:01:24  644k  9 54.6M    9 5438k    0     0  1430k      0  0:00:39  0:00:03  0:00:36 1430k 15 54.6M   15 8686k    0     0  1809k      0  0:00:30  0:00:04  0:00:26 1808k 20 54.6M   20 10.9M    0     0  1920k      0  0:00:29  0:00:05  0:00:24 2265k 23 54.6M   23 12.8M    0     0  1925k      0  0:00:29  0:00:06  0:00:23 2562k 27 54.6M   27 15.1M    0     0  1981k      0  0:00:28  0:00:07  0:00:21 2731k 33 54.6M   33 18.4M    0     0  2144k      0  0:00:26  0:00:08  0:00:18 2688k 38 54.6M   38 21.2M    0     0  2214k      0  0:00:25  0:00:09  0:00:16 2604k 45 54.6M   45 24.6M    0     0  2332k      0  0:00:23  0:00:10  0:00:13 2817k 50 54.6M   50 27.3M    0     0  2369k      0  0:00:23  0:00:11  0:00:12 2983k 54 54.6M   54 29.9M    0     0  2392k      0  0:00:23  0:00:12  0:00:11 3029k 59 54.6M   59 32.4M    0     0  2411k      0  0:00:23  0:00:13  0:00:10 2880k 62 54.6M   62 34.0M    0     0  2339k      0  0:00:23  0:00:14  0:00:09 2578k 64 54.6M   64 35.2M    0     0  2272k      0  0:00:24  0:00:15  0:00:09 2143k 68 54.6M   68 37.4M    0     0  2282k      0  0:00:24  0:00:16  0:00:08 2076k 70 54.6M   70 38.5M    0     0  2219k      0  0:00:25  0:00:17  0:00:08 1772k 74 54.6M   74 40.8M    0     0  2224k      0  0:00:25  0:00:18  0:00:07 1708k 77 54.6M   77 42.3M    0     0  2186k      0  0:00:25  0:00:19  0:00:06 1722k 80 54.6M   80 43.8M    0     0  2154k      0  0:00:25  0:00:20  0:00:05 1777k 86 54.6M   86 47.1M    0     0  2212k      0  0:00:25  0:00:21  0:00:04 1977k 91 54.6M   91 49.9M    0     0  2242k      0  0:00:24  0:00:22  0:00:02 2323k 97 54.6M   97 53.1M    0     0  2287k      0  0:00:24  0:00:23  0:00:01 2525k100 54.6M  100 54.6M    0     0  2301k      0  0:00:24  0:00:24 --:--:-- 2817k
[2024-05-19 02:34:55,179] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-19 02:34:55,200] {taskinstance.py:1267} INFO - Marking task as SUCCESS. dag_id=keypoints_dag, task_id=fetch_data, execution_date=20240518T210407, start_date=20240518T210430, end_date=20240518T210455
[2024-05-19 02:34:55,252] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-19 02:34:55,272] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check

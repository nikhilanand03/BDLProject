[2024-05-19 02:29:25,436] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: keypoints_dag.fetch_data scheduled__2024-05-17T00:00:00+00:00 [queued]>
[2024-05-19 02:29:25,439] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: keypoints_dag.fetch_data scheduled__2024-05-17T00:00:00+00:00 [queued]>
[2024-05-19 02:29:25,439] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-19 02:29:25,439] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-05-19 02:29:25,439] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-19 02:29:25,443] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): fetch_data> on 2024-05-17 00:00:00+00:00
[2024-05-19 02:29:25,452] {standard_task_runner.py:52} INFO - Started process 32596 to run task
[2024-05-19 02:29:25,456] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'keypoints_dag', 'fetch_data', 'scheduled__2024-05-17T00:00:00+00:00', '--job-id', '2', '--raw', '--subdir', 'DAGS_FOLDER/preprocess_airflow.py', '--cfg-path', '/var/folders/hr/cn8gd6d15xv_6m22yptdtyhw0000gn/T/tmpfh2puxoe', '--error-file', '/var/folders/hr/cn8gd6d15xv_6m22yptdtyhw0000gn/T/tmphe516gz4']
[2024-05-19 02:29:25,457] {standard_task_runner.py:77} INFO - Job 2: Subtask fetch_data
[2024-05-19 02:29:25,478] {logging_mixin.py:109} INFO - Running <TaskInstance: keypoints_dag.fetch_data scheduled__2024-05-17T00:00:00+00:00 [running]> on host 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa
[2024-05-19 02:29:25,497] {taskinstance.py:1424} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=keypoints_dag
AIRFLOW_CTX_TASK_ID=fetch_data
AIRFLOW_CTX_EXECUTION_DATE=2024-05-17T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-05-17T00:00:00+00:00
[2024-05-19 02:29:25,498] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/hr/cn8gd6d15xv_6m22yptdtyhw0000gn/T
[2024-05-19 02:29:25,498] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -o /Users/nikhilanand/BigDataLabProject/data/train.zip "https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/62891/6855609/compressed/training.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1716100019&Signature=cz%2FG3wvyhW9QcUGYEAJ2bNXo6%2FIgCjqrbvxZGtyEC7%2BuoZkfBknQIlCuccOA82cjZjppreHd9XQcWXHNVvudXozi1iJJhcQzdZoqUzMux3lrBSZGGtZ%2BTYufw53k5WMQ2ByF%2Fm%2FhqJSjTlijkZOfRMJgbJkvGIcbMwIZxOwmXho%2FQjn6XGxSTsbNYaBfDl9%2FFtxqUz7eM42Y6WHzRbCbinHh0NqnRIAWNwh6ixYM7GRdSVhJiMmS7Ed9oLMvTUQBgi6qgyRB5BDejTJ6v31mCQdJcO0Nb53bbmzxl42nFMnBEtw3HhVgkD4rJcDbQXiWLRs0C1rKC5w2jGDA2c10sw%3D%3D&response-content-disposition=attachment%3B+filename%3Dtraining.csv.zip"']
[2024-05-19 02:29:25,510] {subprocess.py:85} INFO - Output:
[2024-05-19 02:29:25,544] {subprocess.py:89} INFO -   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
[2024-05-19 02:29:25,544] {subprocess.py:89} INFO -                                  Dload  Upload   Total   Spent    Left  Speed
[2024-05-19 02:29:49,416] {subprocess.py:89} INFO -   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0 54.6M    0 95928    0     0  68717      0  0:13:53  0:00:01  0:13:52 68716  2 54.6M    2 1230k    0     0   573k      0  0:01:37  0:00:02  0:01:35  573k  8 54.6M    8 4989k    0     0  1586k      0  0:00:35  0:00:03  0:00:32 1586k 14 54.6M   14 8205k    0     0  1979k      0  0:00:28  0:00:04  0:00:24 1979k 19 54.6M   19 10.8M    0     0  2156k      0  0:00:25  0:00:05  0:00:20 2250k 26 54.6M   26 14.5M    0     0  2404k      0  0:00:23  0:00:06  0:00:17 3085k 30 54.6M   30 16.7M    0     0  2378k      0  0:00:23  0:00:07  0:00:16 3147k 32 54.6M   32 17.9M    0     0  2246k      0  0:00:24  0:00:08  0:00:16 2659k 35 54.6M   35 19.2M    0     0  2146k      0  0:00:26  0:00:09  0:00:17 2284k 38 54.6M   38 20.9M    0     0  2107k      0  0:00:26  0:00:10  0:00:16 2058k 44 54.6M   44 24.4M    0     0  2249k      0  0:00:24  0:00:11  0:00:13 2055k 49 54.6M   49 27.0M    0     0  2281k      0  0:00:24  0:00:12  0:00:12 2139k 54 54.6M   54 29.7M    0     0  2305k      0  0:00:24  0:00:13  0:00:11 2401k 58 54.6M   58 32.0M    0     0  2315k      0  0:00:24  0:00:14  0:00:10 2624k 61 54.6M   61 33.3M    0     0  2244k      0  0:00:24  0:00:15  0:00:09 2519k 66 54.6M   66 36.2M    0     0  2294k      0  0:00:24  0:00:16  0:00:08 2394k 72 54.6M   72 39.7M    0     0  2371k      0  0:00:23  0:00:17  0:00:06 2589k 78 54.6M   78 43.0M    0     0  2428k      0  0:00:23  0:00:18  0:00:05 2753k 82 54.6M   82 45.0M    0     0  2396k      0  0:00:23  0:00:19  0:00:04 2624k 87 54.6M   87 48.0M    0     0  2442k      0  0:00:22  0:00:20  0:00:02 3050k 90 54.6M   90 49.3M    0     0  2328k      0  0:00:24  0:00:21  0:00:03 2430k 92 54.6M   92 50.6M    0     0  2340k      0  0:00:23  0:00:22  0:00:01 2236k 97 54.6M   97 53.2M    0     0  2357k      0  0:00:23  0:00:23 --:--:-- 2097k100 54.6M  100 54.6M    0     0  2342k      0  0:00:23  0:00:23 --:--:-- 2118k
[2024-05-19 02:29:49,419] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-19 02:29:49,436] {taskinstance.py:1267} INFO - Marking task as SUCCESS. dag_id=keypoints_dag, task_id=fetch_data, execution_date=20240517T000000, start_date=20240518T205925, end_date=20240518T205949
[2024-05-19 02:29:49,452] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-19 02:29:49,466] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check

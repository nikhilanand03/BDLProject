[2024-05-19 02:34:05,499] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: keypoints_dag.fetch_data manual__2024-05-18T21:04:03.051208+00:00 [queued]>
[2024-05-19 02:34:05,502] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: keypoints_dag.fetch_data manual__2024-05-18T21:04:03.051208+00:00 [queued]>
[2024-05-19 02:34:05,502] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-19 02:34:05,502] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-05-19 02:34:05,502] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-19 02:34:05,506] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): fetch_data> on 2024-05-18 21:04:03.051208+00:00
[2024-05-19 02:34:05,514] {standard_task_runner.py:52} INFO - Started process 35795 to run task
[2024-05-19 02:34:05,518] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'keypoints_dag', 'fetch_data', 'manual__2024-05-18T21:04:03.051208+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/preprocess_airflow.py', '--cfg-path', '/var/folders/hr/cn8gd6d15xv_6m22yptdtyhw0000gn/T/tmpbxozfcny', '--error-file', '/var/folders/hr/cn8gd6d15xv_6m22yptdtyhw0000gn/T/tmp372_0pmr']
[2024-05-19 02:34:05,519] {standard_task_runner.py:77} INFO - Job 11: Subtask fetch_data
[2024-05-19 02:34:05,541] {logging_mixin.py:109} INFO - Running <TaskInstance: keypoints_dag.fetch_data manual__2024-05-18T21:04:03.051208+00:00 [running]> on host 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa
[2024-05-19 02:34:05,558] {taskinstance.py:1424} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=keypoints_dag
AIRFLOW_CTX_TASK_ID=fetch_data
AIRFLOW_CTX_EXECUTION_DATE=2024-05-18T21:04:03.051208+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-05-18T21:04:03.051208+00:00
[2024-05-19 02:34:05,559] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/hr/cn8gd6d15xv_6m22yptdtyhw0000gn/T
[2024-05-19 02:34:05,559] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -o /Users/nikhilanand/BDLProject/data/train.zip "https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/62891/6855609/compressed/training.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1716100019&Signature=cz%2FG3wvyhW9QcUGYEAJ2bNXo6%2FIgCjqrbvxZGtyEC7%2BuoZkfBknQIlCuccOA82cjZjppreHd9XQcWXHNVvudXozi1iJJhcQzdZoqUzMux3lrBSZGGtZ%2BTYufw53k5WMQ2ByF%2Fm%2FhqJSjTlijkZOfRMJgbJkvGIcbMwIZxOwmXho%2FQjn6XGxSTsbNYaBfDl9%2FFtxqUz7eM42Y6WHzRbCbinHh0NqnRIAWNwh6ixYM7GRdSVhJiMmS7Ed9oLMvTUQBgi6qgyRB5BDejTJ6v31mCQdJcO0Nb53bbmzxl42nFMnBEtw3HhVgkD4rJcDbQXiWLRs0C1rKC5w2jGDA2c10sw%3D%3D&response-content-disposition=attachment%3B+filename%3Dtraining.csv.zip"']
[2024-05-19 02:34:05,569] {subprocess.py:85} INFO - Output:
[2024-05-19 02:34:05,582] {subprocess.py:89} INFO -   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
[2024-05-19 02:34:05,582] {subprocess.py:89} INFO -                                  Dload  Upload   Total   Spent    Left  Speed
[2024-05-19 02:34:28,265] {subprocess.py:89} INFO -   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0 54.6M    0 81695    0     0  61425      0  0:15:32  0:00:01  0:15:31 61424  1 54.6M    1  891k    0     0   411k      0  0:02:15  0:00:02  0:02:13  411k  7 54.6M    7 3951k    0     0  1267k      0  0:00:44  0:00:03  0:00:41 1267k 12 54.6M   12 6959k    0     0  1697k      0  0:00:32  0:00:04  0:00:28 1697k 17 54.6M   17 9760k    0     0  1913k      0  0:00:29  0:00:05  0:00:24 1973k 20 54.6M   20 11.0M    0     0  1835k      0  0:00:30  0:00:06  0:00:24 2323k 23 54.6M   23 12.9M    0     0  1863k      0  0:00:30  0:00:07  0:00:23 2500k 27 54.6M   27 14.8M    0     0  1872k      0  0:00:29  0:00:08  0:00:21 2250k 29 54.6M   29 16.3M    0     0  1825k      0  0:00:30  0:00:09  0:00:21 1929k 33 54.6M   33 18.0M    0     0  1829k      0  0:00:30  0:00:10  0:00:20 1743k 38 54.6M   38 21.1M    0     0  1946k      0  0:00:28  0:00:11  0:00:17 2084k 44 54.6M   44 24.1M    0     0  2045k      0  0:00:27  0:00:12  0:00:15 2304k 49 54.6M   49 26.8M    0     0  2098k      0  0:00:26  0:00:13  0:00:13 2464k 53 54.6M   53 29.1M    0     0  2119k      0  0:00:26  0:00:14  0:00:12 2663k 57 54.6M   57 31.3M    0     0  2123k      0  0:00:26  0:00:15  0:00:11 2717k 63 54.6M   63 34.7M    0     0  2212k      0  0:00:25  0:00:16  0:00:09 2806k 69 54.6M   69 38.0M    0     0  2281k      0  0:00:24  0:00:17  0:00:07 2850k 75 54.6M   75 41.3M    0     0  2337k      0  0:00:23  0:00:18  0:00:05 2964k 81 54.6M   81 44.3M    0     0  2370k      0  0:00:23  0:00:19  0:00:04 3070k 86 54.6M   86 47.3M    0     0  2414k      0  0:00:23  0:00:20  0:00:03 3299k 92 54.6M   92 50.6M    0     0  2456k      0  0:00:22  0:00:21  0:00:01 3239k 98 54.6M   98 53.5M    0     0  2480k      0  0:00:22  0:00:22 --:--:-- 3161k100 54.6M  100 54.6M    0     0  2465k      0  0:00:22  0:00:22 --:--:-- 2970k
[2024-05-19 02:34:28,268] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-19 02:34:28,288] {taskinstance.py:1267} INFO - Marking task as SUCCESS. dag_id=keypoints_dag, task_id=fetch_data, execution_date=20240518T210403, start_date=20240518T210405, end_date=20240518T210428
[2024-05-19 02:34:28,342] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-19 02:34:28,361] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check

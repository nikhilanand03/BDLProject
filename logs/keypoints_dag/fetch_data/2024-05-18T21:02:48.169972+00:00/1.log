[2024-05-19 02:32:50,359] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: keypoints_dag.fetch_data manual__2024-05-18T21:02:48.169972+00:00 [queued]>
[2024-05-19 02:32:50,361] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: keypoints_dag.fetch_data manual__2024-05-18T21:02:48.169972+00:00 [queued]>
[2024-05-19 02:32:50,362] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2024-05-19 02:32:50,362] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2024-05-19 02:32:50,362] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2024-05-19 02:32:50,365] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): fetch_data> on 2024-05-18 21:02:48.169972+00:00
[2024-05-19 02:32:50,376] {standard_task_runner.py:52} INFO - Started process 34930 to run task
[2024-05-19 02:32:50,381] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'keypoints_dag', 'fetch_data', 'manual__2024-05-18T21:02:48.169972+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/preprocess_airflow.py', '--cfg-path', '/var/folders/hr/cn8gd6d15xv_6m22yptdtyhw0000gn/T/tmpwfur72j_', '--error-file', '/var/folders/hr/cn8gd6d15xv_6m22yptdtyhw0000gn/T/tmprzrqh5tx']
[2024-05-19 02:32:50,382] {standard_task_runner.py:77} INFO - Job 8: Subtask fetch_data
[2024-05-19 02:32:50,404] {logging_mixin.py:109} INFO - Running <TaskInstance: keypoints_dag.fetch_data manual__2024-05-18T21:02:48.169972+00:00 [running]> on host 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa
[2024-05-19 02:32:50,421] {taskinstance.py:1424} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=keypoints_dag
AIRFLOW_CTX_TASK_ID=fetch_data
AIRFLOW_CTX_EXECUTION_DATE=2024-05-18T21:02:48.169972+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-05-18T21:02:48.169972+00:00
[2024-05-19 02:32:50,422] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/hr/cn8gd6d15xv_6m22yptdtyhw0000gn/T
[2024-05-19 02:32:50,422] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -o /Users/nikhilanand/BDLProject/data/train.zip "https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/62891/6855609/compressed/training.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1716100019&Signature=cz%2FG3wvyhW9QcUGYEAJ2bNXo6%2FIgCjqrbvxZGtyEC7%2BuoZkfBknQIlCuccOA82cjZjppreHd9XQcWXHNVvudXozi1iJJhcQzdZoqUzMux3lrBSZGGtZ%2BTYufw53k5WMQ2ByF%2Fm%2FhqJSjTlijkZOfRMJgbJkvGIcbMwIZxOwmXho%2FQjn6XGxSTsbNYaBfDl9%2FFtxqUz7eM42Y6WHzRbCbinHh0NqnRIAWNwh6ixYM7GRdSVhJiMmS7Ed9oLMvTUQBgi6qgyRB5BDejTJ6v31mCQdJcO0Nb53bbmzxl42nFMnBEtw3HhVgkD4rJcDbQXiWLRs0C1rKC5w2jGDA2c10sw%3D%3D&response-content-disposition=attachment%3B+filename%3Dtraining.csv.zip"']
[2024-05-19 02:32:50,434] {subprocess.py:85} INFO - Output:
[2024-05-19 02:32:50,461] {subprocess.py:89} INFO -   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
[2024-05-19 02:32:50,461] {subprocess.py:89} INFO -                                  Dload  Upload   Total   Spent    Left  Speed
[2024-05-19 02:33:15,910] {subprocess.py:89} INFO -   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0 54.6M    0 14223    0     0  20273      0  0:47:04 --:--:--  0:47:04 20260  0 54.6M    0 87626    0     0  71595      0  0:13:19  0:00:01  0:13:18 71589  1 54.6M    1  831k    0     0   363k      0  0:02:33  0:00:02  0:02:31  363k  5 54.6M    5 3280k    0     0   999k      0  0:00:55  0:00:03  0:00:52  999k  9 54.6M    9 5535k    0     0  1298k      0  0:00:43  0:00:04  0:00:39 1298k 14 54.6M   14 8351k    0     0  1599k      0  0:00:34  0:00:05  0:00:29 1843k 18 54.6M   18  9.9M    0     0  1632k      0  0:00:34  0:00:06  0:00:28 2015k 22 54.6M   22 12.5M    0     0  1770k      0  0:00:31  0:00:07  0:00:24 2420k 29 54.6M   29 15.9M    0     0  1970k      0  0:00:28  0:00:08  0:00:20 2604k 35 54.6M   35 19.3M    0     0  2148k      0  0:00:26  0:00:09  0:00:17 2878k 41 54.6M   41 22.7M    0     0  2276k      0  0:00:24  0:00:10  0:00:14 2985k 45 54.6M   45 24.7M    0     0  2250k      0  0:00:24  0:00:11  0:00:13 3010k 51 54.6M   51 28.0M    0     0  2353k      0  0:00:23  0:00:12  0:00:11 3201k 54 54.6M   54 29.7M    0     0  2304k      0  0:00:24  0:00:13  0:00:11 2866k 56 54.6M   56 30.8M    0     0  2219k      0  0:00:25  0:00:14  0:00:11 2351k 58 54.6M   58 32.2M    0     0  2167k      0  0:00:25  0:00:15  0:00:10 1942k 60 54.6M   60 33.2M    0     0  2098k      0  0:00:26  0:00:16  0:00:10 1752k 65 54.6M   65 35.9M    0     0  2132k      0  0:00:26  0:00:17  0:00:09 1594k 70 54.6M   70 38.6M    0     0  2171k      0  0:00:25  0:00:18  0:00:07 1820k 76 54.6M   76 41.6M    0     0  2217k      0  0:00:25  0:00:19  0:00:06 2212k 80 54.6M   80 43.7M    0     0  2213k      0  0:00:25  0:00:20  0:00:05 2355k 84 54.6M   84 45.9M    0     0  2214k      0  0:00:25  0:00:21  0:00:04 2587k 88 54.6M   88 48.3M    0     0  2228k      0  0:00:25  0:00:22  0:00:03 2558k 92 54.6M   92 50.2M    0     0  2217k      0  0:00:25  0:00:23  0:00:02 2385k 95 54.6M   95 52.0M    0     0  2200k      0  0:00:25  0:00:24  0:00:01 2134k 99 54.6M   99 54.2M    0     0  2204k      0  0:00:25  0:00:25 --:--:-- 2165k100 54.6M  100 54.6M    0     0  2197k      0  0:00:25  0:00:25 --:--:-- 2113k
[2024-05-19 02:33:15,914] {subprocess.py:93} INFO - Command exited with return code 0
[2024-05-19 02:33:15,931] {taskinstance.py:1267} INFO - Marking task as SUCCESS. dag_id=keypoints_dag, task_id=fetch_data, execution_date=20240518T210248, start_date=20240518T210250, end_date=20240518T210315
[2024-05-19 02:33:15,957] {local_task_job.py:154} INFO - Task exited with return code 0
[2024-05-19 02:33:15,971] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
